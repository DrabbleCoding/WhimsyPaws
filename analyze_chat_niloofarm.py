# -*- coding: utf-8 -*-
"""analyze_chat_niloofarm

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JmZM-WlwpNXHEI4FdzXIxDssJK7rZWX4
"""

# analyze_chat.py

import os
import re
import json
from datetime import datetime
from transformers import pipeline

# Load latest chat history file
def get_latest_chat_file():
    files = sorted([f for f in os.listdir() if f.startswith("chat_history_") and f.endswith(".txt")])
    return files[-1] if files else None

# Format Gemini summarization prompt
def create_summarization_prompt(chat_text, date_str):
    return f"""
{date_str} (Chat):
{chat_text.strip()}

### Output Format (strictly follow this):
{date_str}:
<One emotionally-focused summary sentence>
"""

# Simulated Gemini summarization (swap with API call)
def gemini_summarize(prompt):
    # Replace this with real Gemini API call
    return f"{datetime.now().strftime('%d/%m/%Y')}:\nThe child showed curiosity and energy throughout the session."

# Emotion scoring using Hugging Face
def analyze_summary(summary_text):
    classifier = pipeline(
        "text-classification",
        model="j-hartmann/emotion-english-distilroberta-base",
        return_all_scores=True,
        truncation=True
    )
    entries = re.findall(r"(\d{2}/\d{2}/\d{4}):\n(.+?)(?=\n\d{2}/\d{2}/\d{4}:|\Z)", summary_text, re.DOTALL)

    def score_to_bucket(score): return max(1, int(round(score * 10)))

    results_by_day = {}
    for date, text in entries:
        scores = classifier(text.strip())[0]
        results_by_day[date.strip()] = {s['label']: score_to_bucket(s['score']) for s in scores}

    os.makedirs("output", exist_ok=True)
    with open("output/emotions.json", "w") as f:
        json.dump(results_by_day, f, indent=2)

    return results_by_day

# Main runner
def run_analysis():
    latest_file = get_latest_chat_file()
    if not latest_file:
        print("‚ùå No chat file found.")
        return

    with open(latest_file, "r") as f:
        chat_text = f.read()

    today = datetime.now().strftime("%d/%m/%Y")
    prompt = create_summarization_prompt(chat_text, today)

    print("üîé Summarizing conversation with Gemini...")
    summary = gemini_summarize(prompt)
    print("\nüìã Summary:\n", summary)

    print("\nüìä Analyzing emotional tone...")
    scores = analyze_summary(summary)
    print(json.dumps(scores, indent=2))

if __name__ == "__main__":
    run_analysis()